{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path, start_page, end_page=\"\"):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    if(end_page==\"\"):\n",
    "        end_page=len(doc)\n",
    "    text = \"\"\n",
    "    for page_num in range(start_page - 1, end_page):  # Adjusting for 0-based index\n",
    "        page = doc.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text starting from page 14\n",
    "ipc = extract_text_from_pdf(\"C:\\\\RV\\\\tempdata\\python\\ML\\Similarity\\IPC.pdf\",14,)\n",
    "bnss = extract_text_from_pdf(\"C:\\\\RV\\\\tempdata\\python\\ML\\Similarity\\BNSS.pdf\",14,)\n",
    "bpc = extract_text_from_pdf(\"C:\\\\RV\\\\tempdata\\python\\ML\\Similarity\\BPC.pdf\",15,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T07:08:11.147508Z",
     "iopub.status.busy": "2024-07-21T07:08:11.147071Z",
     "iopub.status.idle": "2024-07-21T07:08:11.156762Z",
     "shell.execute_reply": "2024-07-21T07:08:11.155268Z",
     "shell.execute_reply.started": "2024-07-21T07:08:11.147479Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "  \n",
    "# Remove unnecessary white spaces and combining new lines\n",
    "    text = re.sub(r'[\\r\\n]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "#     # Repeal sections marked with \"rep.\" or \"[Repealed.]\"\n",
    "#     text = re.sub(r'Section \\d+.*?\\s*rep\\..*?(?=Section|$)', '', text, flags=re.DOTALL)\n",
    "#     text = re.sub(r'Section \\d+\\.\\s*\\[Repealed\\.\\].*?(?=Section|$)', '', text, flags=re.DOTALL)\n",
    "    \n",
    "#     text = re.sub(r'\\d+\\*', '', text)\n",
    "    \n",
    "#     # Remove square brackets but keep the content inside\n",
    "#     text = re.sub(r'\\[(.*?)\\]', r'\\1', text)\n",
    "    \n",
    "    \n",
    "#     # Replace terms\n",
    "#     text = re.sub(r'Code of Criminal Procedure \\(Amendment\\) Act \\(\\d+\\)', '#', text)\n",
    "#     text = re.sub(r'Indian Penal Code', '$', text)\n",
    "    \n",
    "     # Replace all numbering\n",
    "#    text = re.sub(r'\\(\\w*\\)|\\(\\d+\\w*\\)|\\d+\\w*|\\w\\.', '.', text)\n",
    "#    text = re.sub(r'-+', '', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_text_to_file(filename, string_to_write):\n",
    "    # Open a file in write mode\n",
    "    file = open(filename, \"w\")\n",
    "\n",
    "    file.write(string_to_write)\n",
    "\n",
    "    # Close the file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_preprocess = preprocess_text(ipc)\n",
    "bnss_preprocess = preprocess_text(bnss)\n",
    "bpc_preprocess = preprocess_text(bpc)\n",
    "write_text_to_file('C:\\\\RV\\\\tempdata\\python\\ML\\Similarity\\ipc.txt',ipc)\n",
    "write_text_to_file('C:\\\\RV\\\\tempdata\\python\\ML\\Similarity\\ipc_preprocess.txt',ipc_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sentences(text):\n",
    "    result = text.split('.')\n",
    "    trimmed_result = [string.strip() for string in result] # Trim\n",
    "    filtered_list = [string for string in trimmed_result if re.search('[a-zA-Z]', string)] # All independent special and numbers will be removed. \n",
    "    remove_firstspecial_list = [string[1:].strip() if re.search('[^a-zA-Z0-9]', string[0]) else string.strip() for string in filtered_list if re.search('[a-zA-Z]', string)] # Special chatacter in first char is removed\n",
    "    remove_numbering = [re.sub(r\"^(?:\\([a-zA-Z]\\)|\\[a-zA-Z]\\)|\\d+\\)|\\(\\d+\\)|\\[\\d+\\]|\\[[a-zA-Z]\\]|[a-zA-Z]\\)|[a-zA-Z]\\()[^\\w\\s]*\", '', item.strip()) for item in remove_firstspecial_list] # Numbering in beginning of the list is removed\n",
    "    trimmed_result_A = [string.strip() for string in remove_numbering] # Trim\n",
    "    return (trimmed_result_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(file, content):\n",
    "    with open(file, \"w\") as file:\n",
    "        for item in content:\n",
    "            file.write(item + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_sentences = convert_to_sentences(ipc_preprocess)\n",
    "bnss_sentences = convert_to_sentences(bnss_preprocess)\n",
    "bpc_sentences = convert_to_sentences(bpc_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_token_to_sentence(sentences):\n",
    "    string_with_token = \"\"\n",
    "    for sentence in sentences:\n",
    "        string_with_token = string_with_token + '[CLS]' + sentence + '[SEP]'\n",
    "    return string_with_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipc_sentences_with_token = add_token_to_sentence(ipc_sentences)\n",
    "bnss_sentences_with_token = add_token_to_sentence(bnss_sentences)\n",
    "bpc_sentences_with_token = add_token_to_sentence(bpc_sentences)\n",
    "#ipc_sentences_with_tokens = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list_to_file('C:\\\\RV\\\\tempdata\\\\python\\\\ML\\Similarity\\\\ipc_sentences.txt',ipc_sentences)\n",
    "write_list_to_file('C:\\\\RV\\\\tempdata\\\\python\\\\ML\\Similarity\\\\bnss_sentences.txt',bnss_sentences)\n",
    "write_list_to_file('C:\\\\RV\\\\tempdata\\\\python\\\\ML\\Similarity\\\\bpc_sentences.txt',bpc_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity(sentences) between ipc and bnss: 0.32755787495583294\n",
      "Cosine Similarity(sentences) between ipc and bpc: 0.010397812270505256\n",
      "Cosine Similarity(sentences) between bnss and bpc: 0.010096575090103047\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "def compute_cosine_similarity(doc1, doc2):\n",
    "    # Initialize the TF-IDF Vectorizer\n",
    "    vectorizer = MultiLabelBinarizer()\n",
    "    \n",
    "    tfidf_matrix_fit = vectorizer.fit([doc1, doc2])\n",
    "\n",
    "    tfidf_matrix_transform = tfidf_matrix_fit.transform([doc1, doc2])\n",
    "    # Compute the cosine similarity\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix_transform[0:1], tfidf_matrix_transform[1:2])\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "    tfidf_matrix_transform,\n",
    "    columns=tfidf_matrix_fit.classes_,\n",
    "    index=[\"IPC\", \"BNSS\"]\n",
    "    )\n",
    "#    print(df)\n",
    "    return similarity_matrix[0][0]\n",
    "\n",
    "    \n",
    "\n",
    "similarity = compute_cosine_similarity(ipc_sentences, bnss_sentences)\n",
    "print(f\"Cosine Similarity(sentences) between ipc and bnss: {similarity}\")\n",
    "\n",
    "similarity = compute_cosine_similarity(ipc_sentences, bpc_sentences)\n",
    "print(f\"Cosine Similarity(sentences) between ipc and bpc: {similarity}\")\n",
    "\n",
    "similarity = compute_cosine_similarity(bnss_sentences, bpc_sentences)\n",
    "print(f\"Cosine Similarity(sentences) between bnss and bpc: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvvny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the sentences and convert them into tensors\n",
    "ipc_sentences_tokenizer = tokenizer(ipc_sentences_with_token, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "bnss_sentences_tokenizer = tokenizer(bnss_sentences_with_token, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "bpc_sentences_tokenizer = tokenizer(bpc_sentences_with_token, return_tensors=\"pt\", truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the embeddings for the sentences\n",
    "with torch.no_grad():\n",
    "    ipc_sentences_embedding = model(**ipc_sentences_tokenizer).last_hidden_state.mean(dim=1)\n",
    "    bnss_sentences_embedding = model(**bnss_sentences_tokenizer).last_hidden_state.mean(dim=1)\n",
    "    bpc_sentences_embedding = model(**bpc_sentences_tokenizer).last_hidden_state.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity(semantic) between ipc and bnss: 0.9756323\n",
      "Cosine Similarity(semantic) between ipc and bpc: 0.950667\n",
      "Cosine Similarity(semantic) between bnss and bpc: 0.96584374\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = cosine_similarity(ipc_sentences_embedding, bnss_sentences_embedding)\n",
    "print(\"Cosine Similarity(semantic) between ipc and bnss: \" + str(cos_similarity[0,0]))\n",
    "\n",
    "cos_similarity = cosine_similarity(ipc_sentences_embedding, bpc_sentences_embedding)\n",
    "print(\"Cosine Similarity(semantic) between ipc and bpc: \" + str(cos_similarity[0,0]))\n",
    "\n",
    "cos_similarity = cosine_similarity(bnss_sentences_embedding, bpc_sentences_embedding)\n",
    "print(\"Cosine Similarity(semantic) between bnss and bpc: \" + str(cos_similarity[0,0]))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5421925,
     "sourceId": 9001238,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
